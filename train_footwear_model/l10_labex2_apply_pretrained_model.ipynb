{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-pR17mdaJbh"
   },
   "source": [
    "# Upload Images\n",
    "\n",
    "Before we can apply pretrained models to classify images, we have to upload the images to the Google Colab environment.\n",
    "\n",
    "The `upload_files` function below can be used to upload files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "p5_O2jyfam9V"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "def upload_files():\n",
    "    uploaded = files.upload()\n",
    "    for k, v in uploaded.items():\n",
    "        open(k, 'wb').write(v)\n",
    "    return list(uploaded.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQFuXkbxDLsN"
   },
   "source": [
    "Run the following code block to upload your image files. This function returns a list of image paths which will be stored in `files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rSeEiaLqzsFD"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'upload_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mupload_files\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'upload_files' is not defined"
     ]
    }
   ],
   "source": [
    "files = upload_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGLEAp3dWeqU"
   },
   "source": [
    "# Using Pre-trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmxnZTI_bi9p"
   },
   "source": [
    "Initialize model with the best available weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqORBRuYbM9u"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhvQYDLAbO50"
   },
   "source": [
    "Before using the pre-trained models, one must preprocess the image (resize with right resolution/interpolation, apply inference transforms, rescale the values etc). There is no standard way to do this as it depends on how a given model was trained. It can vary across model families, variants or even weight versions. Using the correct preprocessing method is critical and failing to do so may lead to decreased accuracy or incorrect outputs.\n",
    "\n",
    "All the necessary information for the inference transforms of each pre-trained model is provided on its weights documentation. To simplify inference, TorchVision bundles the necessary preprocessing transforms into each model weight. These are accessible via the weight.transforms attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4AxsuUcbyOn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image\n",
    "\n",
    "# Load images from paths into tensors\n",
    "imgs = []\n",
    "for fp in files:\n",
    "    img = read_image(fp)\n",
    "    imgs.append(img)\n",
    "\n",
    "# Initialize the inference transforms\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Apply inference preprocessing transforms\n",
    "if len(imgs) == 1:\n",
    "    # Add a batch dimension after preprocessing\n",
    "    batch = preprocess(imgs[0]).unsqueeze(0)\n",
    "else:\n",
    "    # Stack multiple preprocessed image\n",
    "    batch = torch.stack([preprocess(img) for img in imgs])\n",
    "\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRTDuxsneCZf"
   },
   "source": [
    "Use the model and print the predicted category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmJ2dicsbPOV"
   },
   "outputs": [],
   "source": [
    "# Prediction the probability of each class\n",
    "logits = model(batch)\n",
    "probas = logits.softmax(1)\n",
    "preds = probas.argmax(1)\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    class_id = preds[i].item()\n",
    "    score = probas[i][class_id].item()\n",
    "    category_name = weights.meta[\"categories\"][class_id]\n",
    "    print(f\"{category_name}: {100 * score:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIuRcVX3K6cQ"
   },
   "source": [
    "# Exercises: Change the model\n",
    "\n",
    "You need to change the pre-trained model to be something else. Please have a look [here](https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights) and pick one model of your choice. Then write the code below to apply a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53jYTbREf9VB"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
